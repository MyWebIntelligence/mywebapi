# üìã FINALISATION DE LA MIGRATION - LEGACY ‚Üí API

**Date d'analyse**: 2025-11-20
**Analys√© par**: Claude
**Statut global**: üü° Migration ~70% compl√®te

---

## üìä VUE D'ENSEMBLE

### R√©sum√© Ex√©cutif
- **Code Legacy**: ~9,256 lignes Python (_legacy/)
- **Fonctionnalit√©s migr√©es**: ~70%
- **Fonctionnalit√©s manquantes**: 30 items identifi√©s
- **√âtat production**: ‚úÖ Pr√™t pour use cases de base
- **√âtat avanc√©**: üü° Fonctionnalit√©s avanc√©es en migration

### R√©partition par Priorit√©
- üî¥ **Critique** (6 t√¢ches): Fonctionnalit√©s core manquantes
- üü° **Haute** (8 t√¢ches): Fonctionnalit√©s importantes avec workarounds
- üü¢ **Moyenne** (10 t√¢ches): Am√©liorations et optimisations
- ‚ö™ **Basse** (6 t√¢ches): Nice-to-have et qualit√© de vie

---

## üî¥ PRIORIT√â CRITIQUE

### 1. Pipeline Embeddings (D√âSACTIV√â dans V2)
**Statut**: ‚ö†Ô∏è Code existe mais d√©sactiv√©
**Legacy**: `_legacy/embedding_pipeline.py` (377 lignes)
**API Actuelle**: Code comment√© dans V2 (moved to projetV3)

**Fonctionnalit√©s manquantes**:
- ‚ùå G√©n√©ration embeddings pour paragraphes
- ‚ùå Recherche par similarit√© cosinus
- ‚ùå Clustering s√©mantique
- ‚ùå Index ANN (FAISS, Annoy)
- ‚ùå Batch processing embeddings
- ‚ùå Support multi-providers (OpenAI, Cohere, Local)

**Fichiers concern√©s**:
- `app/services/embedding_service.py` (d√©sactiv√©)
- `app/api/v2/endpoints/paragraphs.py:generate_embeddings()` (d√©sactiv√©)

**T√¢ches**:
1. [ ] R√©activer `embedding_service.py`
2. [ ] Impl√©menter provider abstraction (OpenAI, Cohere, SentenceTransformers)
3. [ ] Cr√©er endpoint `POST /api/v2/paragraphs/generate-embeddings`
4. [ ] Cr√©er endpoint `POST /api/v2/paragraphs/search-similar`
5. [ ] Impl√©menter index FAISS pour ANN search
6. [ ] Ajouter batch processing avec Celery
7. [ ] Cr√©er endpoints health check providers
8. [ ] Tests unitaires et d'int√©gration
9. [ ] Documentation API

**Estimation**: 5-8 jours
**D√©pendances**: projetV3 integration strategy

---

### 2. Recherche S√©mantique (Semantic Search)
**Statut**: ‚ö†Ô∏è Table `similarities` existe mais endpoints manquants
**Legacy**: `_legacy/semantic_pipeline.py` (518 lignes)
**API Actuelle**: Mod√®le `Similarity` existe, pas d'endpoints

**Fonctionnalit√©s manquantes**:
- ‚ùå Calcul similarit√©s entre paragraphes
- ‚ùå Recherche par requ√™te texte
- ‚ùå Clustering automatique
- ‚ùå D√©tection doublons s√©mantiques
- ‚ùå Recommandations de contenu similaire

**Fichiers concern√©s**:
- `app/models/paragraph.py` (relation `similarities_as_source/target`)
- Besoin nouveau: `app/services/semantic_search_service.py`
- Besoin nouveau: `app/api/v2/endpoints/semantic_search.py`

**T√¢ches**:
1. [ ] Cr√©er `SemanticSearchService`
2. [ ] Impl√©menter calcul similarit√©s batch
3. [ ] Endpoint `POST /api/v2/paragraphs/compute-similarities`
4. [ ] Endpoint `GET /api/v2/paragraphs/{id}/similar`
5. [ ] Endpoint `POST /api/v2/search/semantic` (full-text semantic)
6. [ ] Clustering avec K-Means/DBSCAN
7. [ ] D√©tection doublons automatique
8. [ ] Background task Celery pour calculs
9. [ ] Cache Redis pour r√©sultats fr√©quents
10. [ ] Tests et documentation

**Estimation**: 4-6 jours
**D√©pendances**: T√¢che #1 (Embeddings)

---

### 3. Extraction M√©dias Dynamiques (Playwright)
**Statut**: ‚ùå Non migr√©
**Legacy**: `_legacy/core.py:extract_dynamic_medias()` (100+ lignes)
**API Actuelle**: Extraction statique uniquement

**Fonctionnalit√©s manquantes**:
- ‚ùå Lancement Chromium headless
- ‚ùå Attente network idle + lazy loading
- ‚ùå Extraction m√©dias JavaScript-rendered
- ‚ùå Support data-src, data-lazy-src, data-original
- ‚ùå Screenshots de pages

**Fichiers concern√©s**:
- Besoin nouveau: `app/services/dynamic_media_service.py`
- Extension: `app/services/media_extraction.py`

**T√¢ches**:
1. [ ] Ajouter d√©pendance Playwright au projet
2. [ ] Cr√©er `DynamicMediaService`
3. [ ] Impl√©menter extraction avec Chromium headless
4. [ ] G√©rer timeout et network idle
5. [ ] Support lazy-loading patterns
6. [ ] Ajouter option dans `crawl_land()`: `dynamic_media=True`
7. [ ] Endpoint `POST /api/v2/expressions/{id}/extract-dynamic-media`
8. [ ] Tests avec sites r√©els (SPA React/Vue)
9. [ ] Documentation usage et configuration

**Estimation**: 3-5 jours
**Risques**: Performance (headless browser lourd), timeouts

---

### 4. Int√©gration SerpAPI (Endpoints manquants)
**Statut**: ‚ö†Ô∏è Service existe mais pas d'endpoints API
**Legacy**: `_legacy/core.py:fetch_serpapi_url_list()` (400+ lignes)
**API Actuelle**: `app/services/serpapi_service.py` existe

**Fonctionnalit√©s manquantes**:
- ‚ùå Endpoints API pour recherche
- ‚ùå Pagination automatique
- ‚ùå Windows temporelles (day/week/month)
- ‚ùå Multi-engines (Google/Bing/DuckDuckGo)
- ‚ùå Filtrage par dates

**Fichiers concern√©s**:
- `app/services/serpapi_service.py` (service existe ‚úÖ)
- Besoin nouveau: `app/api/v2/endpoints/serpapi.py`
- Besoin nouveau: `app/schemas/serpapi.py`

**T√¢ches**:
1. [ ] Cr√©er sch√©mas Pydantic (request/response)
2. [ ] Endpoint `POST /api/v2/lands/{land_id}/serpapi-search`
3. [ ] Support param√®tres: query, engine, lang, datestart, dateend, timestep
4. [ ] Ajouter r√©sultats comme expressions automatiquement
5. [ ] Background task Celery pour recherches longues
6. [ ] Gestion rate limits API
7. [ ] Caching r√©sultats (√©viter requ√™tes dupliqu√©es)
8. [ ] Tests avec mocks SerpAPI
9. [ ] Documentation exemples d'usage

**Estimation**: 2-3 jours

---

### 5. Gestion Expression Links (Endpoints manquants)
**Statut**: ‚ö†Ô∏è Table `expression_links` existe mais pas d'endpoints
**Legacy**: `_legacy/core.py:link_expression()` + graphe
**API Actuelle**: Mod√®le existe, CRUD basique existe

**Fonctionnalit√©s manquantes**:
- ‚ùå Endpoints pour lister liens d'une expression
- ‚ùå Analyse de graphe (PageRank, centralit√©)
- ‚ùå Visualisation graphe
- ‚ùå D√©tection clusters/communaut√©s
- ‚ùå Export graphe (GraphML, JSON)

**Fichiers concern√©s**:
- `app/models/expression.py` (relations `outgoing_links`, `incoming_links` ‚úÖ)
- `app/crud/crud_link.py` (CRUD basique ‚úÖ)
- Besoin nouveau: `app/api/v2/endpoints/graph.py`
- Besoin nouveau: `app/services/graph_analysis_service.py`

**T√¢ches**:
1. [ ] Endpoint `GET /api/v2/expressions/{id}/links` (outgoing/incoming)
2. [ ] Endpoint `GET /api/v2/lands/{land_id}/graph` (vue compl√®te)
3. [ ] Cr√©er `GraphAnalysisService` avec NetworkX
4. [ ] Calcul PageRank pour expressions
5. [ ] D√©tection communaut√©s (Louvain, Girvan-Newman)
6. [ ] M√©triques centralit√© (betweenness, closeness, degree)
7. [ ] Export formats (GraphML, D3.js JSON, Cytoscape JSON)
8. [ ] Endpoint `GET /api/v2/lands/{land_id}/graph/metrics`
9. [ ] Tests et documentation

**Estimation**: 4-5 jours

---

### 6. Archive.org Fallback (√Ä v√©rifier)
**Statut**: ü§î Incertain si migr√© pour expressions
**Legacy**: `_legacy/core.py:crawl_expression()` fallback Archive.org
**API Actuelle**: Migr√© pour domaines, pas s√ªr pour expressions

**Fonctionnalit√©s manquantes**:
- ‚ùì Fallback Archive.org si expression HTTP 404/500
- ‚ùì Recherche snapshot le plus proche
- ‚ùì Extraction contenu archiv√© avec Trafilatura

**Fichiers concern√©s**:
- `app/core/domain_crawler.py` (Archive.org pour domaines ‚úÖ)
- `app/core/crawler_engine.py` (√† v√©rifier pour expressions)

**T√¢ches**:
1. [ ] V√©rifier si fallback Archive.org existe pour expressions
2. [ ] Si non: Impl√©menter dans `crawler_engine.py`
3. [ ] Ajouter colonne `source` dans `expressions` (direct/archive/trafilatura)
4. [ ] Tests avec URLs archiv√©es
5. [ ] Documentation

**Estimation**: 1-2 jours
**D√©pendance**: Investigation pr√©alable

---

## üü° PRIORIT√â HAUTE

### 7. Tag Management Complet
**Statut**: ‚ö†Ô∏è Endpoints V1 incomplets
**Legacy**: Tags avec hi√©rarchie
**API Actuelle**: CRUD basique, pas de tagged_content endpoints

**Fonctionnalit√©s manquantes**:
- ‚ùå Hi√©rarchie tags (parent/children)
- ‚ùå CRUD pour `tagged_content`
- ‚ùå Extraction automatique tags depuis contenu
- ‚ùå Export tags (matrix, content) comme legacy
- ‚ùå Statistiques usage tags

**Fichiers concern√©s**:
- `app/api/v1/endpoints/tags.py` (basique)
- Besoin: `app/api/v2/endpoints/tagged_content.py`
- Besoin: `app/services/tag_extraction_service.py`

**T√¢ches**:
1. [ ] Migrer endpoints tags vers V2 avec pagination
2. [ ] Endpoint `POST /api/v2/tags/{tag_id}/children` (hi√©rarchie)
3. [ ] CRUD complet tagged_content
4. [ ] Endpoint `POST /api/v2/expressions/{id}/tag` (ajout tag manuel)
5. [ ] Service extraction automatique tags (NER, keywords)
6. [ ] Endpoint `POST /api/v2/lands/{land_id}/auto-tag`
7. [ ] Export tags (matrix CSV, content CSV) comme legacy
8. [ ] Statistiques tags par land
9. [ ] Tests et documentation

**Estimation**: 3-4 jours

---

### 8. Dictionary Management Complet
**Statut**: ‚ö†Ô∏è Endpoints partiels (populate, stats)
**Legacy**: CRUD complet + stemming
**API Actuelle**: Populate + stats uniquement

**Fonctionnalit√©s manquantes**:
- ‚ùå CRUD complet sur `Word` table
- ‚ùå Endpoint ajout/suppression mots individuels
- ‚ùå Endpoint liste dictionnaire
- ‚ùå Stemming fran√ßais explicite
- ‚ùå Import/export dictionnaire

**Fichiers concern√©s**:
- `app/services/dictionary_service.py` (populate exists ‚úÖ)
- Besoin: `app/api/v2/endpoints/dictionary.py`
- Besoin: `app/crud/crud_word.py`

**T√¢ches**:
1. [ ] Cr√©er `crud_word.py` avec CRUD complet
2. [ ] Endpoint `POST /api/v2/lands/{land_id}/dictionary/words`
3. [ ] Endpoint `GET /api/v2/lands/{land_id}/dictionary/words`
4. [ ] Endpoint `DELETE /api/v2/lands/{land_id}/dictionary/words/{word_id}`
5. [ ] Endpoint `POST /api/v2/lands/{land_id}/dictionary/import` (CSV/TXT)
6. [ ] Endpoint `GET /api/v2/lands/{land_id}/dictionary/export`
7. [ ] Stemming automatique avec NLTK Snowball
8. [ ] Tests stemming fran√ßais
9. [ ] Documentation

**Estimation**: 2-3 jours

---

### 9. Quality Scoring Automatique
**Statut**: ‚ö†Ô∏è Service existe mais pas int√©gr√© au crawl
**Legacy**: Calcul int√©gr√© dans crawl
**API Actuelle**: `quality_scorer.py` existe mais pas utilis√©

**Fonctionnalit√©s manquantes**:
- ‚ùå Scoring automatique pendant crawl
- ‚ùå Endpoints scoring manuel
- ‚ùå M√©triques quality d√©taill√©es
- ‚ùå Seuils quality configurables

**Fichiers concern√©s**:
- `app/services/quality_scorer.py` (service ‚úÖ)
- `app/core/crawler_engine.py` (int√©grer scoring)
- Besoin: `app/api/v2/endpoints/quality.py`

**T√¢ches**:
1. [ ] Int√©grer `quality_scorer` dans pipeline crawl
2. [ ] Endpoint `POST /api/v2/expressions/{id}/compute-quality`
3. [ ] Endpoint `POST /api/v2/lands/{land_id}/compute-quality` (batch)
4. [ ] M√©triques d√©taill√©es: readability, structure, completeness
5. [ ] Configuration seuils dans settings
6. [ ] Filtrage expressions par quality_score
7. [ ] Background task Celery pour batch
8. [ ] Tests avec contenu r√©el
9. [ ] Documentation m√©triques

**Estimation**: 2-3 jours

---

### 10. Consolidation Compl√®te
**Statut**: ‚ö†Ô∏è Placeholder dans `crawling_service.py`
**Legacy**: `_legacy/core.py:consolidate_land()` (200+ lignes)
**API Actuelle**: Fonction vide

**Fonctionnalit√©s legacy manquantes**:
```python
def consolidate_land():
    # 1. Suppression anciens liens et m√©dias
    # 2. Recalcul relevance sans OpenRouter
    # 3. Extraction liens sortants (Markdown + HTML)
    # 4. Ajout documents manquants
    # 5. Recr√©ation liens avec gestion IntegrityError
    # 6. Extraction et recr√©ation m√©dias
```

**T√¢ches**:
1. [ ] Impl√©menter suppression anciens liens/m√©dias
2. [ ] Recalcul relevance pour toutes expressions
3. [ ] Extraction liens sortants depuis readable
4. [ ] Cr√©ation nouvelles expressions si URLs manquantes
5. [ ] Reconstruction graphe de liens
6. [ ] Re-extraction m√©dias depuis HTML
7. [ ] Gestion erreurs IntegrityError (doublons)
8. [ ] Background task Celery
9. [ ] Tests avec land r√©el
10. [ ] Documentation

**Estimation**: 3-4 jours

---

### 11. SEO Rank Analysis
**Statut**: ‚ùå Placeholder uniquement
**Legacy**: `_legacy/core.py:fetch_seorank_for_url()` + update batch
**API Actuelle**: Colonne `seo_rank` existe, pas d'impl√©mentation

**Fonctionnalit√©s manquantes**:
- ‚ùå Int√©gration API SEOrank (Moz, SimilarWeb, Facebook)
- ‚ùå M√©triques: domain authority, page authority, social shares
- ‚ùå Batch update avec filtres
- ‚ùå Rate limiting et retry

**Fichiers concern√©s**:
- Besoin nouveau: `app/services/seorank_service.py`
- `app/models/expression.py` (colonne `seo_rank` JSON ‚úÖ)

**T√¢ches**:
1. [ ] Cr√©er `SeoRankService` avec API client
2. [ ] Support Moz API (domain authority, page authority)
3. [ ] Support SimilarWeb API (traffic metrics)
4. [ ] Support Facebook API (social shares)
5. [ ] Endpoint `POST /api/v2/expressions/{id}/fetch-seorank`
6. [ ] Endpoint `POST /api/v2/lands/{land_id}/update-seorank` (batch)
7. [ ] Param√®tres: force_refresh, delay, filtres
8. [ ] Rate limiting avec backoff exponentiel
9. [ ] Background task Celery
10. [ ] Tests avec mocks API
11. [ ] Documentation

**Estimation**: 4-5 jours
**D√©pendances**: Acc√®s APIs (Moz, SimilarWeb, Facebook)

---

### 12. Canonical URL Management
**Statut**: ‚ö†Ô∏è Colonne existe mais pas utilis√©e
**Legacy**: Pas explicite dans legacy
**API Actuelle**: Colonne `canonical_url` existe

**Fonctionnalit√©s manquantes**:
- ‚ùå D√©tection canonical URL depuis HTML `<link rel="canonical">`
- ‚ùå D√©duplication expressions par canonical
- ‚ùå Fusion m√©tadonn√©es doublons
- ‚ùå Redirection automatique vers canonical

**Fichiers concern√©s**:
- `app/models/expression.py` (colonne `canonical_url` ‚úÖ)
- `app/core/content_extractor.py` (ajouter d√©tection)

**T√¢ches**:
1. [ ] Extraction canonical URL depuis HTML
2. [ ] Sauvegarde dans colonne `canonical_url`
3. [ ] D√©tection doublons (m√™me canonical)
4. [ ] Endpoint `POST /api/v2/lands/{land_id}/deduplicate-expressions`
5. [ ] Strat√©gie fusion: conserver plus complet
6. [ ] Tests avec sites ayant canonical URLs
7. [ ] Documentation

**Estimation**: 2-3 jours

---

### 13. Heuristics pour Domaines
**Statut**: ‚ùå Non migr√©
**Legacy**: Mapping domaines logiques (ex: twitter.com/user ‚Üí domaine)
**API Actuelle**: Pas d'√©quivalent

**Fonctionnalit√©s manquantes**:
- ‚ùå Configuration heuristics (patterns regex)
- ‚ùå Extraction domaine logique vs technique
- ‚ùå Mapping configurables
- ‚ùå Update batch domaines selon nouvelles heuristics

**Fichiers concern√©s**:
- Besoin nouveau: `app/core/heuristics.py`
- `app/core/crawler_engine.py` (int√©grer)

**T√¢ches**:
1. [ ] Cr√©er module `heuristics.py`
2. [ ] Configuration patterns dans settings (JSON/YAML)
3. [ ] Fonction `extract_logical_domain(url, heuristics)`
4. [ ] Endpoint `POST /api/v2/domains/update-heuristics`
5. [ ] Tests avec URLs complexes (subdomains, paths)
6. [ ] Documentation exemples patterns

**Estimation**: 2 jours

---

### 14. Export Tags (Legacy)
**Statut**: ‚ùå Non migr√©
**Legacy**: `_legacy/export.py:export_tags()` (matrix, content)
**API Actuelle**: Pas d'export tags

**Fonctionnalit√©s manquantes**:
- ‚ùå Export tags matrix CSV
- ‚ùå Export tags content CSV

**Fichiers concern√©s**:
- Besoin: Extension `app/services/export_service_sync.py`

**T√¢ches**:
1. [ ] Impl√©menter `export_tags_matrix()`
2. [ ] Impl√©menter `export_tags_content()`
3. [ ] Endpoint `POST /api/v2/export/tags` (param√®tre type)
4. [ ] Tests export
5. [ ] Documentation formats

**Estimation**: 1-2 jours
**D√©pendance**: T√¢che #7 (Tag Management)

---

## üü¢ PRIORIT√â MOYENNE

### 15. Semantic Pipeline (TF-IDF, LDA, NMF)
**Statut**: ‚ùå Non migr√©
**Legacy**: `_legacy/semantic_pipeline.py` (518 lignes)
**API Actuelle**: Aucun √©quivalent

**Fonctionnalit√©s manquantes**:
- ‚ùå TF-IDF vectorization
- ‚ùå Topic modeling (LDA, NMF)
- ‚ùå Extraction keywords automatique
- ‚ùå Named Entity Recognition (NER)

**T√¢ches**:
1. [ ] Cr√©er `SemanticPipelineService`
2. [ ] Impl√©menter TF-IDF avec scikit-learn
3. [ ] Topic modeling LDA/NMF
4. [ ] Extraction keywords top-N
5. [ ] NER avec spaCy (multilangue)
6. [ ] Endpoint `POST /api/v2/lands/{land_id}/analyze-topics`
7. [ ] Endpoint `GET /api/v2/lands/{land_id}/keywords`
8. [ ] Tests et documentation

**Estimation**: 4-5 jours

---

### 16. Sentiment Analysis Batch
**Statut**: ‚ö†Ô∏è Service existe mais endpoints limit√©s
**Legacy**: Int√©gr√© dans crawl
**API Actuelle**: `sentiment_service.py` existe

**Fonctionnalit√©s manquantes**:
- ‚ùå Batch processing toutes expressions d'un land
- ‚ùå Statistiques sentiment par land
- ‚ùå √âvolution sentiment temporelle

**T√¢ches**:
1. [ ] Endpoint `POST /api/v2/lands/{land_id}/analyze-sentiment` (batch)
2. [ ] Endpoint `GET /api/v2/lands/{land_id}/sentiment-stats`
3. [ ] Graphique √©volution temporelle (par date published)
4. [ ] Background task Celery
5. [ ] Tests et documentation

**Estimation**: 1-2 jours

---

### 17. Media Analysis Compl√®te
**Statut**: ‚ö†Ô∏è Endpoint existe mais features limit√©es
**Legacy**: `_legacy/media_analyzer.py` (296 lignes)
**API Actuelle**: `media_processor.py` basique

**Fonctionnalit√©s manquantes**:
- ‚ùå Perceptual hashing (dHash, pHash)
- ‚ùå D√©tection doublons par hash
- ‚ùå Object detection (YOLO, ResNet)
- ‚ùå OCR texte dans images
- ‚ùå NSFW detection

**T√¢ches**:
1. [ ] Impl√©menter perceptual hashing (imagehash)
2. [ ] D√©tection doublons par similarit√© hash
3. [ ] Object detection avec TensorFlow/PyTorch
4. [ ] OCR avec Tesseract/EasyOCR
5. [ ] NSFW detection (NudeNet ou API)
6. [ ] Colonnes: `detected_objects`, `text_content` (existent ‚úÖ)
7. [ ] Endpoint `POST /api/v2/media/{id}/analyze-advanced`
8. [ ] Tests avec images r√©elles
9. [ ] Documentation

**Estimation**: 5-7 jours

---

### 18. Crawl Statistics Enrichies
**Statut**: ‚ö†Ô∏è Stats basiques existent
**Legacy**: Statistiques d√©taill√©es
**API Actuelle**: Stats limit√©es

**Fonctionnalit√©s manquantes**:
- ‚ùå Distribution HTTP status codes
- ‚ùå Distribution par depth
- ‚ùå Timeline crawl (expressions/jour)
- ‚ùå Performance metrics (temps moyen/expression)

**T√¢ches**:
1. [ ] Endpoint `GET /api/v2/lands/{land_id}/crawl-stats`
2. [ ] M√©triques: distributions, timeline, performance
3. [ ] Graphiques pr√™ts pour dashboard
4. [ ] Cache Redis pour stats lourdes
5. [ ] Documentation

**Estimation**: 2-3 jours

---

### 19. User Management Complet
**Statut**: ‚ö†Ô∏è Authentification existe, gestion limit√©e
**API Actuelle**: JWT auth ‚úÖ, endpoints utilisateurs limit√©s

**Fonctionnalit√©s manquantes**:
- ‚ùå Gestion utilisateurs admin (CRUD)
- ‚ùå R√¥les et permissions
- ‚ùå R√©initialisation mot de passe
- ‚ùå Gestion sessions actives
- ‚ùå Audit logs complets

**T√¢ches**:
1. [ ] Endpoint `GET /api/v2/users` (admin only)
2. [ ] Endpoint `POST /api/v2/users` (cr√©ation admin)
3. [ ] Endpoint `PUT /api/v2/users/{user_id}` (update)
4. [ ] Endpoint `DELETE /api/v2/users/{user_id}`
5. [ ] Syst√®me r√¥les/permissions (RBAC)
6. [ ] Reset password flow (email + token)
7. [ ] Endpoint `GET /api/v2/users/me/sessions`
8. [ ] Endpoint `POST /api/v2/users/me/logout-all`
9. [ ] Audit logs d√©taill√©s
10. [ ] Tests et documentation

**Estimation**: 4-5 jours

---

### 20. Pagination Standardis√©e
**Statut**: ‚ö†Ô∏è V2 a pagination mais pas V1
**API Actuelle**: Incoh√©rence V1/V2

**T√¢ches**:
1. [ ] Standardiser pagination V1 (cursor-based)
2. [ ] Helper pagination dans dependencies
3. [ ] Documentation standards pagination
4. [ ] Tests tous endpoints pagin√©s

**Estimation**: 1-2 jours

---

### 21. Error Handling Standardis√©
**Statut**: ‚ö†Ô∏è V2 a format standard, V1 non
**API Actuelle**: Incoh√©rence

**T√¢ches**:
1. [ ] Migrer V1 vers format erreur V2
2. [ ] Catalogue error codes complet
3. [ ] Handler exceptions global
4. [ ] Documentation error codes
5. [ ] Tests error handling

**Estimation**: 1-2 jours

---

### 22. Validation LLM Avanc√©e
**Statut**: ‚ö†Ô∏è Basique existe
**API Actuelle**: `llm_validation_service.py` basique

**Fonctionnalit√©s manquantes**:
- ‚ùå Multi-providers (OpenAI, Anthropic, Local)
- ‚ùå Prompts configurables
- ‚ùå Extraction m√©tadonn√©es via LLM (r√©sum√©, entit√©s)
- ‚ùå Classification automatique

**T√¢ches**:
1. [ ] Provider abstraction (OpenRouter, OpenAI, Anthropic)
2. [ ] Templates prompts configurables
3. [ ] Endpoint `POST /api/v2/expressions/{id}/llm-extract-metadata`
4. [ ] Endpoint `POST /api/v2/expressions/{id}/llm-classify`
5. [ ] Caching r√©ponses LLM (eviter co√ªts)
6. [ ] Tests avec mocks LLM
7. [ ] Documentation

**Estimation**: 3-4 jours

---

### 23. Content Deduplication
**Statut**: ‚ùå Non migr√©
**Legacy**: Pas explicite
**API Actuelle**: Aucune d√©duplication

**Fonctionnalit√©s manquantes**:
- ‚ùå D√©tection doublons par contenu (hash)
- ‚ùå D√©tection doublons s√©mantiques (embeddings)
- ‚ùå Fusion doublons automatique

**T√¢ches**:
1. [ ] Hash contenu (SHA256 de `readable`)
2. [ ] Colonne `content_hash` dans `expressions`
3. [ ] D√©tection doublons exacts
4. [ ] D√©tection doublons s√©mantiques (cosine similarity)
5. [ ] Endpoint `POST /api/v2/lands/{land_id}/find-duplicates`
6. [ ] Endpoint `POST /api/v2/lands/{land_id}/merge-duplicates`
7. [ ] Tests et documentation

**Estimation**: 3-4 jours

---

### 24. Webhooks et Notifications
**Statut**: ‚ùå Non existant
**Legacy**: Pas dans legacy
**API Actuelle**: Pas de webhooks

**Fonctionnalit√©s manquantes**:
- ‚ùå Webhooks fin de crawl
- ‚ùå Notifications email
- ‚ùå WebSocket notifications temps-r√©el

**T√¢ches**:
1. [ ] Mod√®le `Webhook` (url, events, secret)
2. [ ] Service `WebhookService` (delivery, retry)
3. [ ] √âv√©nements: crawl_completed, crawl_failed, job_completed
4. [ ] Endpoint `POST /api/v2/webhooks`
5. [ ] CRUD webhooks
6. [ ] Signature HMAC pour s√©curit√©
7. [ ] Retry avec backoff
8. [ ] Tests avec mock server
9. [ ] Documentation

**Estimation**: 3-4 jours

---

## ‚ö™ PRIORIT√â BASSE

### 25. CLI Interface Moderne
**Statut**: ‚ùå Legacy CLI non migr√©
**Legacy**: `_legacy/cli.py` (24 commandes)
**API Actuelle**: API uniquement

**T√¢ches**:
1. [ ] Client CLI moderne (Typer ou Click)
2. [ ] Commandes principales: crawl, export, stats
3. [ ] Configuration fichier ~/.mywebapi/config.yaml
4. [ ] Authentification JWT depuis CLI
5. [ ] Progress bars pour op√©rations longues
6. [ ] Tests CLI
7. [ ] Documentation

**Estimation**: 5-7 jours

---

### 26. Web Dashboard (UI)
**Statut**: ‚ùå Non existant
**API Actuelle**: API seulement

**T√¢ches**:
1. [ ] Architecture frontend (React, Vue, Svelte)
2. [ ] Authentification JWT
3. [ ] Pages: lands, expressions, domaines, m√©dias
4. [ ] Visualisation graphe (D3.js, Cytoscape)
5. [ ] Dashboard statistiques
6. [ ] Lancement crawls
7. [ ] Exports
8. [ ] Tests E2E (Playwright)
9. [ ] Documentation

**Estimation**: 15-20 jours

---

### 27. Tests Coverage
**Statut**: ‚ö†Ô∏è Tests partiels
**API Actuelle**: 6 modules tests

**T√¢ches**:
1. [ ] Tests unitaires services (80%+ coverage)
2. [ ] Tests int√©gration endpoints (90%+ coverage)
3. [ ] Tests E2E workflows complets
4. [ ] Tests performance (load testing)
5. [ ] CI/CD avec coverage reports
6. [ ] Documentation tests

**Estimation**: 8-10 jours

---

### 28. Documentation Compl√®te
**Statut**: ‚ö†Ô∏è OpenAPI auto-g√©n√©r√© uniquement
**API Actuelle**: Pas de guides utilisateur

**T√¢ches**:
1. [ ] Guides utilisateur (Markdown/Sphinx)
2. [ ] Tutoriels pas-√†-pas
3. [ ] Exemples code (Python, curl, JavaScript)
4. [ ] Architecture documentation
5. [ ] API reference compl√®te
6. [ ] Deployment guides
7. [ ] Troubleshooting

**Estimation**: 5-7 jours

---

### 29. Database Migrations (Alembic)
**Statut**: ‚ùå R√©pertoire `migrations/` vide
**API Actuelle**: Pas de migrations

**T√¢ches**:
1. [ ] Setup Alembic
2. [ ] Migrations initiales depuis mod√®les
3. [ ] Script migration legacy ‚Üí API
4. [ ] CI/CD auto-migrations
5. [ ] Documentation

**Estimation**: 2-3 jours

---

### 30. Performance Optimization
**Statut**: ‚ö™ Pas de profiling
**API Actuelle**: Performance non mesur√©e

**T√¢ches**:
1. [ ] Profiling endpoints lents
2. [ ] Optimisation requ√™tes SQL (N+1, indexes)
3. [ ] Caching Redis strat√©gique
4. [ ] Rate limiting par user
5. [ ] Compression responses (gzip)
6. [ ] CDN pour m√©dias
7. [ ] Load balancing
8. [ ] Monitoring (Prometheus, Grafana)
9. [ ] Documentation performance

**Estimation**: 5-7 jours

---

## üìä ESTIMATION GLOBALE

### Par Priorit√©
| Priorit√© | T√¢ches | Jours Min | Jours Max |
|----------|--------|-----------|-----------|
| üî¥ Critique | 6 | 17 | 29 |
| üü° Haute | 8 | 24 | 35 |
| üü¢ Moyenne | 10 | 30 | 44 |
| ‚ö™ Basse | 6 | 40 | 54 |
| **TOTAL** | **30** | **111** | **162** |

### Roadmap Recommand√©e

**Phase 1 - Critique (1-2 mois)**
- T√¢ches #1-6
- Focus: Embeddings, Semantic Search, Dynamic Media, SerpAPI, Links, Archive.org

**Phase 2 - Haute (1.5 mois)**
- T√¢ches #7-14
- Focus: Tags, Dictionary, Quality, Consolidation, SEO, Canonical, Heuristics, Export Tags

**Phase 3 - Moyenne (2 mois)**
- T√¢ches #15-24
- Focus: Semantic Pipeline, Sentiment, Media avanc√©, Stats, Users, Validation LLM

**Phase 4 - Basse (2-3 mois)**
- T√¢ches #25-30
- Focus: CLI, Dashboard, Tests, Docs, Migrations, Performance

**TOTAL ESTIM√â**: 6-8 mois avec 1 d√©veloppeur full-time

---

## üéØ RECOMMANDATIONS STRAT√âGIQUES

### Court Terme (Semaine 1-2)
1. ‚úÖ Valider ce document avec l'√©quipe
2. ‚úÖ Prioriser t√¢ches critiques selon business needs
3. ‚úÖ Setup environnement d√©veloppement
4. üöÄ Commencer par T√¢che #4 (SerpAPI) - Quick win, faible risque

### Moyen Terme (Mois 1-3)
1. üî¥ Impl√©menter toutes t√¢ches critiques
2. üü° 50% t√¢ches haute priorit√©
3. üìä Metrics et monitoring
4. üß™ Tests coverage 60%+

### Long Terme (Mois 4-8)
1. üü¢ Compl√©ter t√¢ches moyenne/basse
2. üé® Dashboard web
3. üìö Documentation compl√®te
4. üöÄ Production-ready √† 100%

---

## üìù NOTES

### Risques Identifi√©s
- **Embeddings**: D√©pendance projetV3, architecture √† clarifier
- **Playwright**: Performance (headless browser lourd)
- **SEO APIs**: Co√ªts et rate limits externes
- **LLM**: Co√ªts OpenRouter/OpenAI, besoin caching agressif

### D√©cisions Techniques N√©cessaires
- [ ] Strat√©gie embeddings: Local (SentenceTransformers) vs Cloud (OpenAI)
- [ ] Provider LLM principal: OpenRouter vs OpenAI vs Anthropic direct
- [ ] Frontend framework: React vs Vue vs Svelte
- [ ] Caching strategy: Redis vs Memcached
- [ ] Message queue: Celery/Redis vs RabbitMQ vs AWS SQS

### Points de Synchronisation
- [ ] Alignment avec projetV3 (embeddings, async features)
- [ ] Migration strategy legacy users
- [ ] Backward compatibility V1 vs deprecation
- [ ] API versioning strategy long-term (V3, V4...)

---

**Document g√©n√©r√© par**: Claude (Anthropic)
**Date**: 2025-11-20
**Version**: 1.0
**Statut**: üìã Pr√™t pour review
