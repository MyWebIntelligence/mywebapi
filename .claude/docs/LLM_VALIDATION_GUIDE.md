# Guide Complet : Validation LLM (OpenRouter)

## üìã Table des mati√®res

1. [Vue d'ensemble](#vue-densemble)
2. [Configuration](#configuration)
3. [Usage](#usage)
4. [Co√ªts et estimation](#co√ªts-et-estimation)
5. [Troubleshooting](#troubleshooting)
6. [Architecture technique](#architecture-technique)

---

## üéØ Vue d'ensemble

La **validation LLM** permet d'utiliser un mod√®le de langage (via OpenRouter) pour valider la pertinence des expressions crawl√©es par rapport au sujet de recherche du land.

### Fonctionnement

1. **Apr√®s crawl** : Pour chaque expression avec `relevance > 0` (pertinent selon mots-cl√©s)
2. **Prompt LLM** : Demande au mod√®le si l'expression est pertinente pour le projet
3. **R√©ponse** : Le LLM r√©pond "oui" ou "non"
4. **Action** :
   - **"oui"** ‚Üí Expression valid√©e (`valid_llm='oui'`)
   - **"non"** ‚Üí `relevance=0`, `valid_llm='non'` (expression rejet√©e)

### Avantages

- ‚úÖ R√©duit les faux positifs (expressions matchant les mots-cl√©s mais hors-sujet)
- ‚úÖ Am√©liore la pr√©cision du corpus
- ‚úÖ Valid√© par un mod√®le de pointe (Claude 3.5 Sonnet par d√©faut)

### Limitations

- ‚ùå Co√ªt par validation (~0.007$ avec Claude 3.5 Sonnet)
- ‚ùå Latence (~2-3s par expression)
- ‚ùå Rate limiting (~60 req/min sur OpenRouter)

---

## üîß Configuration

### √âtape 1 : Obtenir une cl√© API OpenRouter

Voir le guide d√©taill√© : [.claude/tasks/OPENROUTER_SETUP.md](.claude/tasks/OPENROUTER_SETUP.md)

**R√©sum√© rapide :**
1. Cr√©er un compte sur https://openrouter.ai/
2. Obtenir une cl√© API (commence par `sk-or-v1-...`)
3. Ajouter des cr√©dits si n√©cessaire (5-10$ offerts √† l'inscription)

### √âtape 2 : Configuration MyWebIntelligence

Ajouter dans votre fichier `.env` :

```bash
# OpenRouter LLM Validation
OPENROUTER_ENABLED=True
OPENROUTER_API_KEY=sk-or-v1-your-actual-api-key-here
OPENROUTER_MODEL=anthropic/claude-3.5-sonnet
OPENROUTER_TIMEOUT=30
OPENROUTER_MAX_RETRIES=3
```

### √âtape 3 : Red√©marrer les services

```bash
docker compose restart api celery_worker
```

### V√©rification

```bash
# V√©rifier que la config est charg√©e
docker compose exec api python -c "from app.config import settings; print(f'OPENROUTER_ENABLED={settings.OPENROUTER_ENABLED}')"
```

---

## üíª Usage

### Option 1 : Validation pendant le crawl

**Endpoint :** `POST /api/v2/lands/{id}/crawl`

```bash
# 1. Authentification
TOKEN=$(curl -s -X POST "http://localhost:8000/api/v1/auth/login" \
  -H "Content-Type: application/x-www-form-urlencoded" \
  -d "username=admin@example.com&password=changeme" | jq -r .access_token)

# 2. Crawl avec validation LLM
curl -X POST "http://localhost:8000/api/v2/lands/36/crawl" \
  -H "Authorization: Bearer $TOKEN" \
  -H "Content-Type: application/json" \
  -d '{
    "limit": 10,
    "enable_llm": true
  }'
```

**R√©sultat :** Les champs `valid_llm` et `valid_model` sont remplis automatiquement pendant le crawl.

### Option 2 : Reprocessing batch (expressions existantes)

#### Via script CLI

```bash
# Reprocessing d'un land sp√©cifique
docker exec mywebintelligenceapi python -m app.scripts.reprocess_llm_validation --land-id 36

# Avec limite
docker exec mywebintelligenceapi python -m app.scripts.reprocess_llm_validation --land-id 36 --limit 50

# Dry-run (simulation)
docker exec mywebintelligenceapi python -m app.scripts.reprocess_llm_validation --land-id 36 --dry-run

# Force (revalider m√™me si valid_llm existe)
docker exec mywebintelligenceapi python -m app.scripts.reprocess_llm_validation --land-id 36 --force
```

#### Via API

**Endpoint :** `POST /api/v2/lands/{id}/llm-validate`

```bash
# Reprocessing via API
curl -X POST "http://localhost:8000/api/v2/lands/36/llm-validate?limit=50&force=false" \
  -H "Authorization: Bearer $TOKEN"
```

**R√©ponse :**
```json
{
  "land_id": 36,
  "land_name": "giletsjaunes",
  "stats": {
    "total_candidates": 50,
    "processed": 50,
    "validated": 42,
    "rejected": 8,
    "errors": 0,
    "api_calls": 50,
    "total_tokens": 12500
  },
  "message": "LLM validation completed: 42 validated, 8 rejected"
}
```

---

## üí∞ Co√ªts et estimation

### Mod√®les recommand√©s

| Mod√®le | Co√ªt / 1K tokens | Co√ªt par validation | Recommandation |
|--------|------------------|---------------------|----------------|
| `anthropic/claude-3.5-sonnet` | ~$0.015 | ~$0.007 | ‚úÖ Recommand√© (pr√©cis) |
| `anthropic/claude-3-haiku` | ~$0.003 | ~$0.0015 | üí∞ √âconomique |
| `openai/gpt-4o-mini` | ~$0.002 | ~$0.001 | üí∞ Tr√®s √©conomique |

### Estimation mensuelle

**Hypoth√®se :** 1 validation = ~500 tokens (prompt) + 2 tokens (r√©ponse) = 502 tokens

| Expressions/jour | Co√ªt/jour (Claude 3.5) | Co√ªt/mois |
|------------------|------------------------|-----------|
| 100 | $0.70 | $21 |
| 500 | $3.50 | $105 |
| 1000 | $7.00 | $210 |

### Optimisations

1. **Utiliser Claude Haiku** : R√©duction de 70% des co√ªts
2. **Filtrer par relevance** : Valider seulement `relevance >= 2.0`
3. **Valider apr√®s readable** : Contenu plus riche = meilleure validation

---

## üêõ Troubleshooting

### Erreur 401 "Unauthorized"

**Sympt√¥me :**
```
Failed to validate: OpenRouter API error 401: Unauthorized
```

**Solution :**
1. V√©rifier que `OPENROUTER_API_KEY` est correct
2. S'assurer que la cl√© commence par `sk-or-v1-`
3. V√©rifier que `OPENROUTER_ENABLED=True`

### Erreur 429 "Rate Limited"

**Sympt√¥me :**
```
Rate limit hit, waiting Xs before retry
```

**Explication :** OpenRouter limite √† ~60 requ√™tes/minute

**Solution :**
- Le syst√®me retry automatiquement avec backoff exponentiel
- R√©duire `batch_size` si n√©cessaire
- Attendre quelques minutes entre les runs

### Erreur 402 "Insufficient Credits"

**Sympt√¥me :**
```
OpenRouter API error 402: Insufficient credits
```

**Solution :**
1. Ajouter des cr√©dits sur https://openrouter.ai/account
2. V√©rifier le solde : Account ‚Üí Billing

### Timeouts

**Sympt√¥me :**
```
Timeout (attempt 1) ... (attempt 2) ... (attempt 3)
OpenRouter API failed after 3 attempts
```

**Solution :**
1. Augmenter `OPENROUTER_TIMEOUT` dans `.env` (ex: 60)
2. V√©rifier la connectivit√© r√©seau
3. Certains mod√®les sont plus lents ‚Üí changer de mod√®le

### Validation √©choue mais crawl continue

**Comportement normal :** La validation LLM est **non-bloquante**

Si la validation √©choue :
- ‚úÖ Le crawl continue normalement
- ‚úÖ L'expression est sauvegard√©e avec sa relevance calcul√©e
- ‚ùå Les champs `valid_llm` et `valid_model` restent NULL
- ‚ö†Ô∏è Un log ERROR est √©mis

**V√©rification :**
```bash
# Logs de validation
docker logs mywebclient-celery_worker-1 --tail=50 | grep -i "llm"
```

---

## üèóÔ∏è Architecture technique

### Composants

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ  Endpoint API                                               ‚îÇ
‚îÇ  POST /api/v2/lands/{id}/crawl?enable_llm=true            ‚îÇ
‚îÇ  POST /api/v2/lands/{id}/llm-validate                     ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                     ‚îÇ
                     ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ  Celery Task (crawling_task.py)                           ‚îÇ
‚îÇ  - R√©cup√®re flag enable_llm                               ‚îÇ
‚îÇ  - Passe √† SyncCrawlerEngine                              ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                     ‚îÇ
                     ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ  SyncCrawlerEngine (crawler_engine.py)                    ‚îÇ
‚îÇ  - Calcule relevance (mots-cl√©s)                          ‚îÇ
‚îÇ  - Si enable_llm ET relevance > 0 :                       ‚îÇ
‚îÇ    ‚îî‚îÄ Appelle LLMValidationService                        ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                     ‚îÇ
                     ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ  LLMValidationService (llm_validation_service.py)         ‚îÇ
‚îÇ  - validate_expression_relevance_sync()                   ‚îÇ
‚îÇ  - Construit le prompt                                    ‚îÇ
‚îÇ  - Appelle OpenRouter API                                 ‚îÇ
‚îÇ  - Parse "oui"/"non"                                      ‚îÇ
‚îÇ  - Retourne ValidationResult                              ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                     ‚îÇ
                     ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ  OpenRouter API                                            ‚îÇ
‚îÇ  https://openrouter.ai/api/v1/chat/completions            ‚îÇ
‚îÇ  - Mod√®le: anthropic/claude-3.5-sonnet (d√©faut)          ‚îÇ
‚îÇ  - Timeout: 30s (configurable)                            ‚îÇ
‚îÇ  - Retries: 3 (avec backoff)                              ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

### Fichiers impact√©s

| Fichier | Modification | Description |
|---------|-------------|-------------|
| [`llm_validation_service.py`](MyWebIntelligenceAPI/app/services/llm_validation_service.py) | ‚úÖ Ajout m√©thode sync | Wrapper sync pour contexts non-async |
| [`crawler_engine.py`](MyWebIntelligenceAPI/app/core/crawler_engine.py) | ‚úÖ Int√©gration LLM | Validation apr√®s calcul relevance |
| [`crawling_task.py`](MyWebIntelligenceAPI/app/tasks/crawling_task.py) | ‚úÖ Propagation flag | R√©cup√®re `enable_llm` des params |
| [`reprocess_llm_validation.py`](MyWebIntelligenceAPI/app/scripts/reprocess_llm_validation.py) | ‚úÖ Nouveau script | Batch reprocessing |
| [`lands_v2.py`](MyWebIntelligenceAPI/app/api/v2/endpoints/lands_v2.py) | ‚úÖ Nouveau endpoint | API de reprocessing |

### Champs de base de donn√©es

```sql
-- Table: expressions
valid_llm VARCHAR(3)      -- "oui" ou "non"
valid_model VARCHAR(100)  -- Ex: "anthropic/claude-3.5-sonnet"
relevance FLOAT           -- Mis √† 0 si valid_llm='non'
```

### Logique de d√©cision

```python
# Pendant le crawl
if enable_llm and OPENROUTER_ENABLED and relevance > 0:
    validation_result = llm_service.validate_expression_relevance_sync(expr, land)

    expr.valid_llm = 'oui' if validation_result.is_relevant else 'non'
    expr.valid_model = validation_result.model_used

    if not validation_result.is_relevant:
        expr.relevance = 0  # Rejeter l'expression
```

---

## üìä Monitoring

### Logs √† surveiller

```bash
# Logs de validation pendant crawl
docker logs mywebclient-celery_worker-1 --tail=50 -f | grep -i "llm"

# Logs typiques
# ‚úÖ Succ√®s
[INFO] [LLM] Expression 123 validated as relevant by anthropic/claude-3.5-sonnet

# ‚ùå Rejet
[INFO] [LLM] Expression 456 marked as non-relevant by anthropic/claude-3.5-sonnet

# ‚ö†Ô∏è Erreur
[ERROR] [LLM] Validation failed for https://example.com: Rate limit hit
```

### Statistiques de validation

```bash
# V√©rifier les r√©sultats dans la DB
docker exec mywebclient-db-1 psql -U mwi_user -d mwi_db -c "
SELECT
  valid_llm,
  COUNT(*) as count,
  ROUND(AVG(relevance)::numeric, 2) as avg_relevance
FROM expressions
WHERE land_id = 36 AND valid_llm IS NOT NULL
GROUP BY valid_llm;
"
```

**R√©sultat exemple :**
```
 valid_llm | count | avg_relevance
-----------+-------+---------------
 oui       |   142 |          3.45
 non       |    23 |          0.00
```

### M√©triques API

Via l'endpoint de reprocessing, vous obtenez :
```json
{
  "api_calls": 165,
  "total_tokens": 41250,
  "validated": 142,
  "rejected": 23,
  "estimated_cost": 0.61875
}
```

---

## üß™ Tests

### Test rapide de configuration

```bash
# Test avec curl direct sur OpenRouter
curl -X POST "https://openrouter.ai/api/v1/chat/completions" \
  -H "Authorization: Bearer $OPENROUTER_API_KEY" \
  -H "Content-Type: application/json" \
  -H "HTTP-Referer: https://mywebintelligence.io" \
  -H "X-Title: MyWebIntelligence API" \
  -d '{
    "model": "anthropic/claude-3.5-sonnet",
    "messages": [{"role": "user", "content": "R√©ponds juste par oui ou non : Est-ce que Paris est en France ?"}],
    "max_tokens": 10
  }'
```

### Test avec MyWebIntelligence

```bash
# 1. Cr√©er un land de test
LAND_ID=$(curl -s -X POST "http://localhost:8000/api/v2/lands/" \
  -H "Authorization: Bearer $TOKEN" \
  -H "Content-Type: application/json" \
  -d '{
    "name": "test_llm",
    "description": "Test validation LLM",
    "start_urls": ["https://example.com"],
    "words": ["test"]
  }' | jq -r '.id')

# 2. Crawl avec LLM
curl -X POST "http://localhost:8000/api/v2/lands/${LAND_ID}/crawl" \
  -H "Authorization: Bearer $TOKEN" \
  -d '{"limit": 3, "enable_llm": true}'

# 3. V√©rifier les r√©sultats
curl "http://localhost:8000/api/v2/lands/${LAND_ID}/stats" \
  -H "Authorization: Bearer $TOKEN" | jq '.validation_stats'
```

---

## üìñ Ressources compl√©mentaires

- **Configuration OpenRouter** : [.claude/tasks/OPENROUTER_SETUP.md](.claude/tasks/OPENROUTER_SETUP.md)
- **Playbook principal** : [.claude/AGENTS.md](.claude/AGENTS.md)
- **Tests unitaires** : [tests/unit/test_llm_validation_service.py](MyWebIntelligenceAPI/tests/unit/test_llm_validation_service.py)
- **Site OpenRouter** : https://openrouter.ai/
- **Documentation API** : https://openrouter.ai/docs
- **Mod√®les disponibles** : https://openrouter.ai/models

---

**Derni√®re mise √† jour** : 19 octobre 2025
**Version** : 1.0
**Mainteneur** : √âquipe MyWebIntelligence
