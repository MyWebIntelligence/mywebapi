# ğŸ”´ ERREUR FRÃ‰QUENTE : RÃ©sidus de Double Crawler

**Date**: 20 octobre 2025  
**GravitÃ©**: ğŸ”´ **CRITIQUE** â€“ bloque la V2 si l'ancien code parallÃ¨le rÃ©apparaÃ®t

---

## âŒ Le problÃ¨me dÃ©sormais

Depuis la V2, MyWebIntelligence n'utilise **qu'un seul moteur de crawl** :  
`MyWebIntelligenceAPI/app/core/crawler_engine_sync.py`

Tout fragment de code, documentation ou script qui tente encore d'appeler un ancien moteur parallÃ¨le doit Ãªtre supprimÃ©. La majoritÃ© des bugs signalÃ©s depuis la migration provenaient de rÃ©fÃ©rences oubliÃ©es Ã  l'ancien module.

---

## ğŸ—ï¸ Architecture actuelle

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  API FastAPI + Workers Celery (SYNC)       â”‚
â”‚      â””â”€ crawler_engine_sync.py             â”‚
â”‚            â””â”€ Source unique de vÃ©ritÃ©      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

- Plus d'appel Ã  `crawler_engine.py` (supprimÃ©)  
- Plus de stratÃ©gie Â« double moteur Â»  
- Toutes les routes REST, tÃ¢ches Celery et scripts internes doivent dÃ©lÃ©guer au mÃªme module synchrone.

---

## âœ… Checklist obligatoire avant merge

```bash
# VÃ©rifier qu'il ne reste qu'un moteur utilisÃ©
rg "crawler_engine" MyWebIntelligenceAPI/app -g"*.py"
```

- [ ] Aucun import `crawler_engine` (ancienne version parallÃ©lisÃ©e)  
- [ ] Les tests d'intÃ©gration ciblent `crawler_engine_sync.SyncCrawlerEngine`  
- [ ] Les tÃ¢ches Celery et jobs CLI appellent la mÃªme classe  
- [ ] Les scripts de rÃ©paration (`scripts/`) n'exÃ©cutent qu'un seul moteur

---

## ğŸ” Comment dÃ©tecter un rÃ©sidu de l'ancien moteur

1. **Imports** : `from app.core import crawler_engine` â†’ Ã  supprimer immÃ©diatement.  
2. **Nom de classe** : toute mention d'un moteur Â« parallÃ¨le Â» ou Â« multi Â» signale un reliquat Ã  effacer.  
3. **Tests** : toute fixture hÃ©ritÃ©e du moteur parallÃ¨le doit Ãªtre rÃ©Ã©crite pour instancier uniquement `SyncCrawlerEngine`.

### Commandes rapides

```bash
rg "crawler_engine" -g"*.py" app/
rg "parallel" -g"*.py" app/
rg "multi crawler" -g"*.md" .claude/
```

---

## ğŸ§¹ Plan d'assainissement

1. **Supprimer** tout module ou dossier portant encore une rÃ©fÃ©rence explicite Ã  l'ancien moteur parallÃ¨le (`parallel`, `dual_crawler`, `double_crawler`).  
2. **RÃ©viser** la configuration Celery : chaque tÃ¢che doit instancier `SyncCrawlerEngine`.  
3. **Rejouer** les tests mÃ©tiers : `tests/test-crawl-simple.sh` et suites Pytest liÃ©es aux crawls.  
4. **Mettre Ã  jour** la documentation : pointer vers ce fichier et vers `AGENTS.md` section _Crawler Sync only_.

---

## ğŸ“¦ Livrables attendus aprÃ¨s nettoyage

- âœ… Codebase sans import de l'ancien moteur  
- âœ… Scripts de dÃ©bogage mis Ã  jour  
- âœ… Guides de test (`README.md`, quickstarts) rÃ©Ã©crits pour l'unique moteur  
- âœ… Nouveaux tickets ouverts si un comportement dÃ©pendait du parallÃ©lisme supprimÃ©

---

## ğŸš¨ Signaux d'alerte en production

- Croissance d'erreurs `ModuleNotFoundError: crawler_engine`  
- TÃ¢ches Celery bloquÃ©es car elles attendent une coroutine  
- PrÃ©sence de champs hÃ©ritÃ©s du mode parallÃ¨le ou d'options Â« mode parallÃ¨le Â» dans les payloads API

Sur dÃ©tection d'un de ces signaux : rollback immÃ©diat et purge des reliquats.

---

## ğŸ“š RÃ©fÃ©rences utiles

- `.claude/AGENTS.md` â€” section Â« Crawler V2 : sync only Â»  
- `MyWebIntelligenceAPI/app/core/crawler_engine_sync.py` â€” implÃ©mentation unique  
- `tests/test-crawl-simple.sh` â€” script de validation de bout en bout
